networks:
  kafka-net: # External kafka network
    external: true
    name: kafka-net

services:
  connect-group-0:
    image: confluentinc/cp-kafka-connect:${KAFKA_VERSION}
    environment:
      CONNECT_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: connect-group-0
      CONNECT_CONFIG_STORAGE_TOPIC: __connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: ${NUMBER_OF_KAFKA_BROKERS}
      CONNECT_OFFSET_STORAGE_TOPIC: __connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: ${NUMBER_OF_KAFKA_BROKERS}
      CONNECT_STATUS_STORAGE_TOPIC: __connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: ${NUMBER_OF_KAFKA_BROKERS}
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars
    # If you want to use the Confluent Hub installer to d/l component, but make them available
    # when running this offline, spin up the stack once and then run :
    #   docker cp kafka-connect:/usr/share/confluent-hub-components ./data/connect-jars
    volumes:
      - ./data:/data
      - ./config:/data/config:ro
    networks:
      - kafka-net
    # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
    command:
      - bash
      - -c
      - |
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &
        #
        echo "Waiting for Kafka Connect to start listening on localhost â³"
        # cub connect-ready localhost 8083 300
        while : ; do
          curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
          echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
          if [ $$curl_status -eq 200 ] ; then
            break
          fi
          sleep 5 
        done
        echo "--\nBulk creating connectors from /data/config/*.json"
        shopt -s nullglob
        files=(/data/config/*.json)
        if [ $${#files[@]} -eq 0 ]; then
          echo "No JSON files found in /data/config"; sleep infinity
        fi
        
        echo -e "\n--\n+> Creating Connector"
        for f in "$${files[@]}"; do
          echo -e "\n+> Processing file: $$f"
          name=$$(basename "$$f" .json)
          echo "+> PUT connector $$name using $$f"
          resp=$$(curl -s -w "\nHTTP_CODE:%{http_code}" -X PUT -H "Content-Type:application/json" \
          http://localhost:8083/connectors/$$name/config -d @"/data/config/$$name.json")
          body=$$(echo "$$resp" | sed '/HTTP_CODE:/d')
          echo "   HTTP $$http_code"; echo "   Body: $$body"
        done
        echo "--\nConnector list:"; curl -s http://localhost:8083/connectors | jq '.' || curl -s http://localhost:8083/connectors

        sleep infinity

#        for f in "${files[@]}"; do
#          name=$$(basename "$$f" .json)
#          echo "+> PUT connector $$name using $$f"
#          resp=$$(curl -s -w "\nHTTP_CODE:%{http_code}" -X PUT -H "Content-Type:application/json" \
#            http://localhost:8083/connectors/$$name/config -d @"/data/config/$$name.json")
#          http_code=$$(echo "$$resp" | awk -F: '/HTTP_CODE/ {print $$2}')
#          body=$$(echo "$$resp" | sed '/HTTP_CODE:/d')
#          echo "   HTTP $$http_code"; echo "   Body: $$body"
#        done
#        echo "--\nConnector list:"; curl -s http://localhost:8083/connectors | jq '.' || curl -s http://localhost:8083/connectors
